## Задачи с фиксированным временем начала и окончания процесса


## Понятие состояния управляемого динамического процесса


## Требования, накладываемые на понятие «состояние» в динамическом программировании

Пусть имеется изменяющийся во времени объект, на который оказывается внешнее воздействие $u(t)$, трактуемое как управление, пусть также $x(t)$ – некоторое описание этого объекта в момент времени $t$. Если при известном управлении $u(\theta)$, $(\theta \in [t, \hat{t}])$, зная описание $x(t)$ в момент времени $t$, можно однозначно определить его значение $x(\hat{t})$ для любого $\hat{t} > t$, то такое описание называют полным. Неизбыточное полное описание называют состоянием, множество возможных состояний $\textemdash$ пространством состояний. Сам объект, допускающий возможность полного описания, называют динамической системой. Заметим, что во многих случаях состояние можно выбрать неединственным способом.

## Постановка задачи

Управляемая динамическая система, состояние которой $x(t) \in R^n$, управление $u(t)$, время дискретно, т. е. $t in \theta = \{t_s, t_{s+1}, \ldots, t_{f-1}, t_f\}$
$x(t+1)=f(x(t), u(t), t)$
$u(t) \in U(x(t), t) \in R^m$
$x(t_s) = x^s \in X^s$
$x(t_f)=x^f \in X^f$
Переход их $x(t)$ под управлением $u(t)$ сопровождается затратами $q(x(t), u(t), t)$
С учетом вышеуказанных ограничений нужно найти оптимальные управление и траекторию, которая обеспечивает оптимальное значение $Q$:
$$Q^* = Q(x^*[t_s, t_f], u^*[t_s, t_f - 1] =$$
$$= \min_{x[t_s, t_f]; \enspace u[t_s, t_f - 1]}{Q(x[t_s, t_f], u[t_s, t_f - 1])}$$
Пример с аддитивным критерием:
$$Q(x[t_s, t_f], u[t_s, t_f - 1]) = \sum_{t=t_s}^{t_f - 1}{q(x(t),u(t),t)}$$
Ещё есть критерий типа максимума и мультипликативный.

- Определения функции Беллмана при решении «от конца» и «от начала».

Обозначим через $Y_k$ множество состояний, из которых ровно за $k$ шагов динамическая система может попасть в множество конечных состояний $X^f$. При этом $Y_0 = X^f$.

**Определение.** Пусть система находится в состоянии $x \in Y_k$. *Функцией Беллмана* $S_k(x)$ называют функцию оптимальных (!) затрат при переводе динамической системы из $x$ в множество финальных состояний за $k$ шагов:

$$S_k(x) = \min{\sum_{t=t_f-k}^{t_f-1}{q(x(t),u(t),t)}},$$
где минимум берется при условии, что $x(t_f-k)=x$, $x(t+1)=f(x(t), u(t), t)$, $u(t) \in U(x(t), t)$ для $t \in \{t_f-k, \ldots, t_f-1\}$, и $x(t_f) \in X^f$.

 Функция Беллмана $Z_k(x)$ при решении от "начала":
$$Z_{k+1}(x) = \min_
{\substack{\hat{x} \in X_k \\ u \in U(\hat{x}, t_s + k) \\ f(\hat{x},u,t_s+k)=x}}
{Z_k(\hat{x}+q(\hat{x}, u, t_s + k))}$$
Значения $\hat{x}$ и $u$, обеспечивающие этот минимум, обозначим как
$${ \hat{x}^*(x,t_s+k); \quad
\hat{u}^*(x,t_s+k) }$$
Эти пары определяют оптимальные правила поведения. Продолжая этот процесс найдем $Z_N(x)$ для $x \in X_N$.
Получим величину оптимальных затрат при движении из множества начальных состояний в доступные состояния множества $X^f$:
$$Z^*_N = \min_{x \in X^f \cap X_N}{Z_N(x)},$$
а также оптимальное конечное состояние $$x^*_f = x^*(t_f) = \arg{\min_{x \in X^f \cap X_N}{Z_N(x)}}.$$
Отсюда, выполняя обратный ход вычислительного процесса, определим предшествующие оптимальные значения:

$${\begin{gathered}
x^*(t_f-1)=\hat{x}^*(x^*(t_f), t_f-1), \\
u^*(t_f-1)=\hat{u}^*(x^*(t_f), t_f-1), \\
\ldots \\
x^*(t_s)=\hat{x}^*(x^*(t_s+1), t_s), \\
u^*(t_s)=\hat{u}^*(x^*(t_s+1), t_s).
\end{gathered}}$$
**Замечание.** *Запись уравнений Беллмана от начала удобна тогда, когда уравнение динамики $f(\hat{x},\hat{u},t)=x$ однозначно разрешимо относительно $\hat{x}$. При этом в $Z_{k+1}(x)$ минимум можно брать только по независимой переменной $\hat{u}$.*

## Метод рекуррентных уравнений Беллмана при записи «от конца» (вывод, порядок применения)

Обозначим через $Y_k$ множество состояний, из которых ровно за $k$ шагов динамическая система может попасть в множество конечных состояний $X^f$. При этом $Y_0 = X^f$.

**Определение.** Пусть система находится в состоянии $x \in Y_k$. *Функцией Беллмана* $S_k(x)$ называют функцию оптимальных (!) затрат при переводе динамической системы из $x$ в множество финальных состояний за $k$ шагов:

$$S_k(x) = \min{\sum_{t=t_f-k}^{t_f-1}{q(x(t),u(t),t)}},$$
где минимум берется при условии, что $x(t_f-k)=x$, $x(t+1)=f(x(t), u(t), t)$, $u(t) \in U(x(t), t)$ для $t \in \{t_f-k, \ldots, t_f-1\}$, и $x(t_f) \in X^f$.

1. Пусть $x \in Y_1$, тогда осталось выполнить один последний шаг. Находим функцию Беллмана, равную оптимальным затратам при переходе из $x$ в $X^f$.
$$S_1(x) = \min_{\substack{u \in U(x, t_f - 1) \\ f(x, u, t_f - 1)}}{q(x, u, t_f - 1)}.$$
Пусть для состояния $x$ минимум в $S_1(x)$ Достигается при использовании управления $u^*(x,t_f-1)$.
2. Допустим, что $S_1(x),S_2(x), \ldots, S_k(x)$, а также $u^*(x,t_f-1), \ldots, u^*(x,t_f-k)$ уже найденыю
3. Выведем рекуррентное соотношение, связывающее $S_{k+1}(x)$ и $S_k(x)$. Предположим, что $x \in Y_{k+1}$. Найдем величину минимальных затрат при переходе из данного состояния $x$ в $X^f$.
По определению:
$$S_{k+1}(x) = \min_{\substack{
u \in U(x, t_f-k-1) \\
x(t_f-k)=f(x, u, t_f-k-1) \\
x(t+1)=f(x(t), u(t), t) \\
u(t) \in U(x(t), t) \\
t \in \{t_f-k, \ldots, t_f-1\} \\
x(t_f) \in X_f
}}
{q(x,u,t_f-k-1) +
\sum_{t=t_f-k}^{t_f-1}{q(x(t),u(t),t)}}.$$
Поскольку первый элемент $q(\ldots)$ в сумме, стоящей в минимуме, не зависит от группы переменных $x(t), u(t)$ для $t \geq t_f-k$, то минимум по обеим группам переменных можно брать только от оставшейся суммы.

$$S_{k+1}(x) = \min_{\substack{
u \in U(x, t_f-k-1) \\
}}
{q(x,u,t_f-k-1) +
\min_{\substack{
x(t_f-k)=f(x, u, t_f-k-1) \\
x(t+1)=f(x(t), u(t), t) \\
u(t) \in U(x(t), t) \\
t \in \{t_f-k, \ldots, t_f-1\} \\
}}{\sum_{t=t_f-k}^{t_f-1}{q(x(t),u(t),t)}}}.$$
Формальным обоснованием законности этого перехода является лемма о расщеплении операции взятия инфимума. Используя определение функции Беллмана, получим, что для $x \in X_{k+1}$:
$$S_{k+1}(x) = \min_{\substack{u \in U(x, t_f -k - 1) \\ f(x, u, t_f - k - 1) \in Y_k}}
{q(x, u, t_f - k - 1) + S_k(f(x,u,t_f-k-1))}.$$
Из этого уравнения для состояния $x$ определяется, кроме того, значение на данном шаге оптимального уравнения: $u^*(x,t_f-k-1)$. Заметим, что дополнительное ограничение $f(x,u,t_f-k-1) \in Y_k$ появилось в $S_{k+1}(x)$ в силу того, что в нем использована функция $S_k(\hat{x})$, областью определения которой является множество $Y_k$.
4. Таким образом, продолжая процесс до $x \in Y_N$ найдем функцию $S_N(x)$.

## Принцип Беллмана как необходимое и как достаточное условия, формулируемые как «от начала», так и «от конца»

**Как необходимое условие:**
Если система под воздействием оптимального управления попала в некоторый момент времени в состояние $x^*(\tau)$, то оставшиеся такты этого управления будут оптимальны.

Для оптимальности пути $\gamma(x^s, x^f)(x^s \in X^S, \enspace x^f \in X^F)$ необходимо, чтобы при любом его разбиении на две части первая часть пути была оптимальна на участке от множества $X^S$ до $x$ —  начального состояния второй части пути.

**Как достаточное условие:**
Если в каждом текущем состоянии использовать управление, являющееся первым тактом управления, оптимального на оставшемся промежутке движения по отношению к состоянию, в которое попал динамический процесс, то такое управление будет в целом оптимально. 

Для оптимальности пути $\gamma(x^s, x^f)(x^s \in X^S, \enspace x^f \in X^F)$ достаточно, чтобы приход в любое промежуточное состояние этого пути совершался по ребру, которым оканчивается путь, обеспечивающий оптимальный переход в это состояние из вершины $x^s \in X^S$, а вершине $x^f$ соответствовала наименьшая стоимость перехода по сравнению с другими вершинами из $X^F$.


## Связь принципа Беллмана с уравнениями Беллмана

## Запись рекуррентных уравнений Беллмана от начала процесса. Пример использования соотношений Беллмана (аналитическое решение задачи об оптимальном распределении с функцией дохода в виде корня квадратного)

